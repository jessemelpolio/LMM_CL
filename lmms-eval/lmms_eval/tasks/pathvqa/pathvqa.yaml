dataset_path: flaviagiammarino/path-vqa
task: "pathvqa"
test_split: test
validation_split: validation
output_type: generate_until
doc_to_visual: !function utils.pathvqa_doc_to_visual
doc_to_text: !function utils.pathvqa_doc_to_text
doc_to_target: !function utils.pathvqa_doc_to_target
generation_kwargs:
  max_new_tokens: 64
  until:
    - "ASSISTANT:"
metric_list:
  - metric: pathvqa_exact_match
    aggregation: mean
    higher_is_better: true
  - metric: pathvqa_f1
    aggregation: mean
    higher_is_better: true
  - metric: pathvqa_bleu1
    aggregation: mean
    higher_is_better: true
  - metric: pathvqa_bleu2
    aggregation: mean
    higher_is_better: true
  - metric: pathvqa_bleu3
    aggregation: mean
    higher_is_better: true
  - metric: pathvqa_binary_accuracy
    aggregation: !function utils.pathvqa_aggregate_binary_accuracy
    higher_is_better: true
process_results: !function utils.pathvqa_process_results
lmms_eval_specific_kwargs:
  default:
    pre_prompt: "Look at the medical image and answer the following question: "
    post_prompt: "\nFor questions that can be answered with a yes or no, just answer yes or no. Otherwise, provide an answer in the medical domain."
metadata:
  version: 0.0
  description: "PathVQA: A dataset of pathology-related visual question answering"
  paper: "https://arxiv.org/pdf/2003.10286v1.pdf"
  citation: "@article{he2020pathvqa,
            title={PathVQA: 30000+ Questions for Medical Visual Question Answering},
            author={He, Xuehai and Zhang, Yichen and Mou, Luntian and Xing, Eric and Xie, Pengtao},
            journal={arXiv preprint arXiv:2003.10286},
            year={2020}
           }" 